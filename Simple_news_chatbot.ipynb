{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get top n headlines\n",
    "def get_top_3headlines(country='us',category='business',n=3):\n",
    "    '''\n",
    "    A function to get the top n headlines from a specific country and category\n",
    "    Input:\n",
    "        country: A string, representing the country, default 'us'\n",
    "        category: A string, representing the category, default 'business'\n",
    "        n = A integer, representing the top healines to return, default 3\n",
    "            \n",
    "    '''\n",
    "    url = ('https://newsapi.org/v2/top-headlines?'\n",
    "       'country='+country+'&'+'category='+category+\n",
    "       '&apiKey=96fca90198f24422b5135b09ac6ef016')\n",
    "    response = requests.get(url)\n",
    "    for i in range(0,n):\n",
    "        print(response.json()['articles'][i]['title'])\n",
    "        print(response.json()['articles'][i]['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_query(q='india',n=3):\n",
    "    '''\n",
    "    A function to get the top n headlines for a specific keyword\n",
    "    Input:\n",
    "        q: A string, representing interested keyword, default 'india'\n",
    "        n = A integer, representing the top healines to return, default 3\n",
    "            \n",
    "    '''\n",
    "    url = ('https://newsapi.org/v2/top-headlines?'\n",
    "       'q='+ q +\n",
    "       '&apiKey=96fca90198f24422b5135b09ac6ef016')\n",
    "    response = requests.get(url)\n",
    "    totalResults = response.json()['totalResults']\n",
    "    print('There were {} articles for {}'.format(totalResults,q))\n",
    "    print('displaying top 3')\n",
    "    for i in range(0,n):\n",
    "        print(response.json()['articles'][i]['title'])\n",
    "        print(response.json()['articles'][i]['description'])\n",
    "        print(response.json()['articles'][i]['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_everything(source):    \n",
    "    '''\n",
    "    A function to get everything for a specific keyword\n",
    "    Input:\n",
    "        source: A string, representing source, default 'bitcoin'\n",
    "            \n",
    "    '''\n",
    "    url = ('https://newsapi.org/v2/everything?'\n",
    "       'domains='+source+\n",
    "       '&apiKey=96fca90198f24422b5135b09ac6ef016')\n",
    "    response = requests.get(url)\n",
    "    totalResults = response.json()['totalResults']\n",
    "    print('There were {} articles'.format(totalResults))\n",
    "    return(pd.DataFrame.from_records(response.json()['articles']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import io\n",
    "import random\n",
    "import string \n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('popular', quiet=True) # for downloading packages\n",
    "\n",
    "# uncomment the following only the first time\n",
    "# nltk.download('punkt') # first-time use only\n",
    "# nltk.download('wordnet') # first-time use only\n",
    "\n",
    "# Preprocessing\n",
    "lemmer = WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "# Keyword Matching\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "\n",
    "\n",
    "def greeting(sentence):\n",
    "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating response\n",
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokens.iloc[-1] = user_response\n",
    "    TfidfVec = TfidfVectorizer(tokenizer = LemNormalize, stop_words = 'english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx = vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response = robo_response + \"I am sorry! I don't understand you\"\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response + sent_tokens[idx] + '\\n' + raw['url'][idx]\n",
    "        return robo_response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hey, My name is Newsbot. I can get the latest news for you from New york times. If you want to exit, type Bye!\n",
      "There were 3857 articles\n",
      "0                             Be Paranoid About Privacy\n",
      "1     My Cookie’s Better Than Yours: Italy Is in a H...\n",
      "2     Review: Animated Shorts of Every Stripe and Fe...\n",
      "3     Trump Complains About Impeachment After Christ...\n",
      "4            Smashing the Finance Patriarchy With Memes\n",
      "5     Boeing Can’t Fly Its 737 Max, but It’s Ready t...\n",
      "6     In Japanese New Year Dishes, a Family Connects...\n",
      "7                            Christmas Should Humble Us\n",
      "8                        Once Upon a Revolution in Iran\n",
      "9     Dense Fog in Chicago Grounds Flights on Christ...\n",
      "10    As Protests Flare in India, Modi Plays a New P...\n",
      "11                                Joe Biden’s Sharpness\n",
      "12    Hot Flashes, Waxing and Periods: Your Question...\n",
      "13        Where Have All The Christmas Tree Farms Gone?\n",
      "14                         A Yosemite Holiday Tradition\n",
      "15    Uber Founder Travis Kalanick Leaves Board, Sev...\n",
      "16    Shuttered Philadelphia Refinery May Get New Li...\n",
      "17           Recent Commercial Real Estate Transactions\n",
      "18                       The Town That Lost Its Walmart\n",
      "19    Mexican Businesses Worry Tweak to USMCA Trade ...\n",
      "Name: title, dtype: object\n",
      "User : \n",
      "waxing\n",
      "Newsbot: Top news\n",
      "Hot Flashes, Waxing and Periods: Your Questions on Women’s Health\n",
      "https://www.nytimes.com/2019/12/24/well/hot-flashes-waxing-and-periods-your-questions-on-womens-health.html\n",
      "User : \n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\" Hey, My name is Newsbot. I can get the latest news for you from New york times. If you want to exit, type Bye!\")\n",
    "\n",
    "raw = get_everything(source='nytimes.com')    \n",
    "\n",
    "#Tokenisation\n",
    "sent_tokens = raw['title']\n",
    "print(sent_tokens)\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response = user_response.lower()\n",
    "    \n",
    "    if(user_response!='bye'):\n",
    "        if(user_response == 'thanks' or user_response == 'thank you' ):\n",
    "            flag = False\n",
    "            print(\"Newsbot: You are welcome..\")\n",
    "        else:\n",
    "            if(greeting(user_response) != None):\n",
    "                print(\"Newsbot: \"+ greeting(user_response))\n",
    "            else:\n",
    "                print(\"Newsbot: \",end = \"\")\n",
    "                print('Top news')\n",
    "                print(response(user_response))\n",
    "                sent_tokens.drop(sent_tokens.tail(1).index,inplace=True)\n",
    "    else:\n",
    "        flag = False\n",
    "        print(\"Newsbot: Bye! take care..\")    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
